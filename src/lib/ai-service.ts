import { GoogleGenerativeAI } from '@google/generative-ai';
import { createOpenRouterClient, isOpenRouterModel } from './api-config';
import { dictionaryService } from './dictionary-service';
import { OpenAI } from 'openai';

interface AIServiceConfig {
    model: string;
}

interface SRTEntry {
    id: number;
    timecode: string;
    text: string;
}

interface GrammarError {
    text: string
    suggestion: string
    explanation: string
    type: 'grammar' | 'spelling' | 'style'
    startIndex: number
    endIndex: number
}

interface TranslationTone {
    name: string
    description: string
    style: string
}

export const TRANSLATION_TONES: Record<string, TranslationTone> = {
    normal: {
        name: 'Normal',
        description: 'D·ªãch th√¥ng th∆∞·ªùng, ph√π h·ª£p v·ªõi vƒÉn b·∫£n chung',
        style: 'Clear, direct, and neutral translation maintaining the original meaning and context'
    },
    novel: {
        name: 'Truy·ªán trung qu·ªëc',
        description: 'T·ªëi ∆∞u cho d·ªãch ti·ªÉu thuy·∫øt Trung Qu·ªëc',
        style: 'D·ªãch theo phong c√°ch ti·ªÉu thuy·∫øt Trung Qu·ªëc, d·ªãch t√™n ra d·∫°ng h√°n vi·ªát, gi·ªØ vƒÉn phong ti·ªÉu thuy·∫øt, nh∆∞ng s·ª≠ d·ª•ng t·ª´ ng·ªØ d·ªÖ hi·ªÉu.'
    },
    academic: {
        name: 'Academic',
        description: 'T·ªëi ∆∞u cho d·ªãch vƒÉn b·∫£n khoa h·ªçc v√† chuy√™n ng√†nh',
        style: 'Technical and specialized language with precise terminology, complex sentence structures, and detailed explanations'
    }
}

interface EnhancementOptions {
    improveStyle: boolean
    formalLevel: 'casual' | 'neutral' | 'formal'
    tone: 'friendly' | 'professional' | 'academic'
    preserveContext: boolean
}

interface ImageTranslationOptions {
    targetLanguage: string;
    preserveContext: boolean;
    tone: string;
}

class AIService {
    private config: AIServiceConfig = {
        model: 'gemini-2.0-flash'
    };

    setModel(model: string) {
        this.config.model = model;
        // Save to localStorage
        if (typeof window !== 'undefined') {
            localStorage.setItem('preferredModel', model);
        }
    }

    getModel(): string {
        return this.config.model;
    }

    loadSavedModel() {
        if (typeof window !== 'undefined') {
            const savedModel = localStorage.getItem('preferredModel');
            if (savedModel) {
                this.config.model = savedModel;
            }
        }
    }

    async processWithAI(prompt: string): Promise<string> {
        if (isOpenRouterModel(this.config.model)) {
            return this.processWithOpenRouter(prompt);
        } else {
            return this.processWithLocalModel(prompt);
        }
    }

    private async processWithOpenRouter(prompt: string): Promise<string> {
        const openRouterKey = process.env.NEXT_PUBLIC_OPENROUTER_API_KEY;
        if (!openRouterKey) {
            throw new Error('OpenRouter API key is not configured');
        }

        const client = createOpenRouterClient(openRouterKey);

        try {
            console.log('üì§ Sending request to OpenRouter...');
            const completion = await client.chat.completions.create({
                model: this.config.model,
                messages: [
                    { role: 'user', content: prompt }
                ]
            });

            const result = completion.choices[0].message.content || '';
            return result;
        } catch (error) {
            console.error('‚ùå OpenRouter error:', {
                model: this.config.model,
                error: error instanceof Error ? error.message : 'Unknown error',
                timestamp: new Date().toISOString()
            });
            throw new Error('Failed to process with OpenRouter');
        }
    }

    private async processWithLocalModel(prompt: string): Promise<string> {
        if (this.config.model === 'gemini-2.0-flash' || this.config.model === 'gemini-2.0-flash-lite' || this.config.model === 'gemini-2.5-pro-exp-03-25') {
            const geminiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;
            if (!geminiKey) {
                throw new Error('Gemini API key is not configured');
            }

            try {
                console.log(`üì§ Sending request to ${this.config.model}...`);
                const genAI = new GoogleGenerativeAI(geminiKey);
                const geminiModel = genAI.getGenerativeModel({ model: this.config.model });
                let generationConfig = {
                    temperature: 1,
                    topP: 0.95,
                    topK: 40,
                    maxOutputTokens: 8192
                };

                const chatSession = geminiModel.startChat({
                    generationConfig,
                    history: []
                });

                const result = await chatSession.sendMessage(prompt);
                return result.response.text();
            } catch (error) {
                console.error('‚ùå Gemini error:', {
                    model: this.config.model,
                    error: error instanceof Error ? error.message : 'Unknown error',
                    timestamp: new Date().toISOString()
                });
                throw new Error('Failed to process with Gemini');
            }
        } else if (this.config.model === 'gpt-4o-mini' || this.config.model === 'gpt-4o') {
            const gptKey = process.env.NEXT_PUBLIC_OPENAI_API_KEY;
            if (!gptKey) {
                throw new Error('OpenAI API key is not configured');
            }

            try {
                console.log('üì§ Sending request to GPT-4o Mini...');
                const client = new OpenAI({
                    apiKey: gptKey,
                    dangerouslyAllowBrowser: true
                });

                const completion = await client.chat.completions.create({
                    model: this.config.model,
                    messages: [
                        { role: 'user', content: prompt }
                    ],
                    temperature: 0.7,
                    max_tokens: 4000
                });

                const result = completion.choices[0].message.content || '';
                return result;
            } catch (error) {
                console.error('‚ùå GPT error:', {
                    model: this.config.model,
                    error: error instanceof Error ? error.message : 'Unknown error',
                    timestamp: new Date().toISOString()
                });
                throw new Error('Failed to process with GPT');
            }
        } else {
            throw new Error('Unsupported model');
        }
    }

    // Translation specific method
    async translate(
        text: string,
        targetLanguage: string,
        preserveContext: boolean,
        tone: string = 'normal',
        onProgress?: (current: number, total: number) => void
    ): Promise<string> {
        // Ki·ªÉm tra text tr·ªëng
        if (!text.trim()) {
            return '';
        }

        // T·ªëi ∆∞u k√≠ch th∆∞·ªõc chunk d·ª±a tr√™n model
        const MAX_CHUNK_LENGTH = 3000;

        // Chu·∫©n h√≥a xu·ªëng d√≤ng
        const normalizedText = text.replace(/\r\n/g, '\n');

        // T√°ch vƒÉn b·∫£n th√†nh c√°c ƒëo·∫°n d·ª±a tr√™n xu·ªëng d√≤ng k√©p
        const paragraphs = normalizedText.split(/\n\s*\n/).filter(p => p.trim());

        // N·∫øu vƒÉn b·∫£n ng·∫Øn, x·ª≠ l√Ω tr·ª±c ti·∫øp
        if (text.length <= MAX_CHUNK_LENGTH) {
            onProgress?.(1, 1);
            const prompt = this.createTranslationPrompt(text, targetLanguage, preserveContext, { tone });
            const result = await this.processWithAI(prompt);
            return dictionaryService.applyDictionary(result);
        }

        // Nh√≥m c√°c ƒëo·∫°n th√†nh c√°c chunk
        const chunks: string[] = [];
        let currentChunk = '';

        for (const paragraph of paragraphs) {
            // N·∫øu ƒëo·∫°n qu√° d√†i, chia nh·ªè th√†nh c√°c c√¢u
            if (paragraph.length > MAX_CHUNK_LENGTH) {
                const sentences = paragraph.match(/[^.!?]+[.!?]+/g) || [paragraph];
                for (const sentence of sentences) {
                    if (currentChunk.length + sentence.length > MAX_CHUNK_LENGTH && currentChunk) {
                        chunks.push(currentChunk.trim());
                        currentChunk = sentence;
                    } else {
                        currentChunk = currentChunk ? `${currentChunk} ${sentence}` : sentence;
                    }
                }
            }
            // N·∫øu kh√¥ng, th√™m c·∫£ ƒëo·∫°n v√†o chunk
            else {
                if (currentChunk.length + paragraph.length > MAX_CHUNK_LENGTH) {
                    chunks.push(currentChunk.trim());
                    currentChunk = paragraph;
                } else {
                    currentChunk = currentChunk ? `${currentChunk}\n\n${paragraph}` : paragraph;
                }
            }
        }

        // Th√™m chunk cu·ªëi c√πng n·∫øu c√≤n
        if (currentChunk) {
            chunks.push(currentChunk.trim());
        }

        // D·ªãch t·ª´ng chunk
        const translatedChunks: string[] = [];
        let previousContext = '';

        for (let i = 0; i < chunks.length; i++) {
            onProgress?.(i + 1, chunks.length);

            const chunk = chunks[i];
            const isFirstChunk = i === 0;
            const isLastChunk = i === chunks.length - 1;

            // T·∫°o prompt v·ªõi context
            let prompt = this.createTranslationPrompt(
                chunk,
                targetLanguage,
                preserveContext,
                {
                    previousContext: isFirstChunk ? '' : previousContext,
                    isFirstChunk,
                    isLastChunk,
                    totalChunks: chunks.length,
                    currentChunk: i + 1,
                    tone
                }
            );

            try {
                const result = await this.processWithAI(prompt);
                const processedResult = await dictionaryService.applyDictionary(result);
                translatedChunks.push(processedResult);

                // L∆∞u context cho chunk ti·∫øp theo
                previousContext = processedResult.slice(-200); // L·∫•y 200 k√Ω t·ª± cu·ªëi l√†m context

                // Log ti·∫øn ƒë·ªô
                console.log(`‚úì Completed chunk ${i + 1}/${chunks.length}`);
            } catch (error) {
                console.error(`Error translating chunk ${i + 1}:`, error);
                // N·∫øu l·ªói, th·ª≠ l·∫°i v·ªõi chunk nh·ªè h∆°n
                const subChunks = chunk.split(/[.!?] /).filter(Boolean);
                let subTranslated = '';
                for (const subChunk of subChunks) {
                    try {
                        const subPrompt = this.createTranslationPrompt(subChunk, targetLanguage, preserveContext, { tone });
                        const subResult = await this.processWithAI(subPrompt);
                        subTranslated += subResult + ' ';
                    } catch (e) {
                        console.error('Sub-chunk translation failed:', e);
                        subTranslated += subChunk + ' '; // Gi·ªØ nguy√™n text g·ªëc n·∫øu l·ªói
                    }
                }
                translatedChunks.push(subTranslated.trim());
            }
        }

        // K·∫øt h·ª£p c√°c chunk ƒë√£ d·ªãch
        return translatedChunks.join('\n\n');
    }

    private createTranslationPrompt(
        text: string,
        targetLanguage: string,
        preserveContext: boolean,
        options?: {
            previousContext?: string;
            isFirstChunk?: boolean;
            isLastChunk?: boolean;
            totalChunks?: number;
            currentChunk?: number;
            tone?: string;
        }
    ): string {
        const translationTone = TRANSLATION_TONES[options?.tone || 'normal'];

        let prompt = `B·∫°n l√† m·ªôt chuy√™n gia d·ªãch thu·∫≠t. H√£y d·ªãch ƒëo·∫°n vƒÉn sau sang ${targetLanguage}.

Phong c√°ch: ${translationTone.style}

B·ªëi c·∫£nh:
${preserveContext ? '- Gi·ªØ nguy√™n ng·ªØ c·∫£nh, phong c√°ch, gi·ªçng ƒëi·ªáu v√† thu·∫≠t ng·ªØ g·ªëc' : '- T·∫≠p trung v√†o s·ª± r√µ r√†ng v√† ch√≠nh x√°c'}
${options?.previousContext ? `\nNg·ªØ c·∫£nh tr∆∞·ªõc ƒë√≥:\n${options.previousContext}` : ''}
${options?.totalChunks ? `\nPh·∫ßn ${options.currentChunk}/${options.totalChunks}` : ''}

Y√™u c·∫ßu:
- D·ªãch ch√≠nh x√°c nh∆∞ng v·∫´n ƒë·∫£m b·∫£o t·ª± nhi√™n v√† m·∫°ch l·∫°c
- Gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng (ƒëo·∫°n vƒÉn, nh·∫•n m·∫°nh)
- Duy tr√¨ t√≠nh nh·∫•t qu√°n v·ªÅ thu·∫≠t ng·ªØ v√† phong c√°ch
- Ch·ªâ tr·∫£ v·ªÅ b·∫£n d·ªãch, kh√¥ng gi·∫£i th√≠ch th√™m, kh√¥ng m·ªü ngo·∫∑c ch√∫ th√≠ch hay g√¨ c·∫£
- ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng b·∫£n d·ªãch d·ªÖ hi·ªÉu
VƒÉn b·∫£n c·∫ßn d·ªãch:
${text}`;

        return prompt;
    }

    private splitTextIntoChunks(text: string, maxLength: number): string[] {
        const chunks: string[] = [];
        let currentChunk = '';
        let currentLength = 0;

        // Helper function to calculate effective length considering Chinese characters
        const getEffectiveLength = (text: string): number => {
            let length = 0;
            for (let i = 0; i < text.length; i++) {
                // Check if character is Chinese (CJK Unified Ideographs range)
                if (/[\u4e00-\u9fff]/.test(text[i])) {
                    length += 4; // Chinese character counts as 4 characters
                } else {
                    length += 1;
                }
            }
            return length;
        };

        // Split text into sentences
        const sentences = text.match(/[^.!?]+[.!?]+/g) || [text];

        for (const sentence of sentences) {
            const sentenceEffectiveLength = getEffectiveLength(sentence);

            // If current chunk is empty, always add the sentence regardless of length
            if (currentChunk === '') {
                currentChunk = sentence;
                currentLength = sentenceEffectiveLength;
                continue;
            }

            // If adding this sentence would exceed maxLength
            if (currentLength + sentenceEffectiveLength > maxLength) {
                chunks.push(currentChunk.trim());
                currentChunk = sentence;
                currentLength = sentenceEffectiveLength;
            } else {
                currentChunk += sentence;
                currentLength += sentenceEffectiveLength;
            }
        }

        // Add the last chunk if it's not empty
        if (currentChunk.trim().length > 0) {
            chunks.push(currentChunk.trim());
        }

        return chunks;
    }

    // Content type detection for better summarization
    private detectContentType(text: string): 'article' | 'technical' | 'narrative' | 'conversation' {
        const technicalPatterns = /(algorithm|implementation|function|class|method|api|documentation|technical|specification)/i;
        const conversationPatterns = /([""'].*?[""']:|^[A-Za-z]+:)/m;
        const narrativePatterns = /(chapter|scene|character|plot|story|novel)/i;

        if (technicalPatterns.test(text)) return 'technical';
        if (conversationPatterns.test(text)) return 'conversation';
        if (narrativePatterns.test(text)) return 'narrative';
        return 'article';
    }

    // Enhanced summarization method
    async summarize(text: string, language: string, type: string = 'concise'): Promise<string> {
        // Handle empty text
        if (!text.trim()) {
            return '';
        }

        // Detect content type for better prompting
        const contentType = this.detectContentType(text);

        // Calculate optimal chunk size based on content length
        const MAX_CHUNK_LENGTH = 4000;
        let chunks: string[] = [];

        if (text.length > MAX_CHUNK_LENGTH) {
            chunks = this.splitTextIntoChunks(text, MAX_CHUNK_LENGTH);
        } else {
            chunks = [text];
        }

        // Process each chunk and combine results
        const summaries: string[] = [];
        for (const chunk of chunks) {
            const prompt = this.createSummaryPrompt(chunk, language, type, contentType, chunks.length > 1);
            const summary = await this.processWithAI(prompt);
            summaries.push(summary);
        }

        // Combine and refine final summary if multiple chunks
        if (summaries.length > 1) {
            const combinedSummary = summaries.join('\n\n');
            const finalPrompt = this.createFinalSummaryPrompt(combinedSummary, language, type);
            return this.processWithAI(finalPrompt);
        }

        return summaries[0];
    }

    private createSummaryPrompt(
        text: string,
        language: string,
        type: string,
        contentType: string,
        isChunked: boolean
    ): string {
        const basePrompt = `H√£y t√≥m t·∫Øt vƒÉn b·∫£n sau b·∫±ng ${language}.

Y√™u c·∫ßu chung:
- ƒê·∫£m b·∫£o t√≠nh ch√≠nh x√°c v√† m·∫°ch l·∫°c
- Gi·ªØ nguy√™n c√°c thu·∫≠t ng·ªØ chuy√™n ng√†nh quan tr·ªçng
- T·∫≠p trung v√†o n·ªôi dung c√≥ gi√° tr·ªã th√¥ng tin cao
- S·ª≠ d·ª•ng ng√¥n ng·ªØ r√µ r√†ng, d·ªÖ hi·ªÉu
${isChunked ? '- ƒê√¢y l√† m·ªôt ph·∫ßn c·ªßa vƒÉn b·∫£n d√†i h∆°n, h√£y t·∫≠p trung v√†o c√°c ƒëi·ªÉm ch√≠nh trong ph·∫ßn n√†y' : ''}

Lo·∫°i n·ªôi dung: ${contentType}
`;

        switch (type) {
            case 'concise':
                return `${basePrompt}
Y√™u c·∫ßu c·ª• th·ªÉ:
- T√≥m t·∫Øt ng·∫Øn g·ªçn, s√∫c t√≠ch
- ƒê·ªô d√†i kho·∫£ng 20-25% vƒÉn b·∫£n g·ªëc
- T·∫≠p trung v√†o nh·ªØng ƒëi·ªÉm quan tr·ªçng nh·∫•t

C·∫•u tr√∫c:
## T√≥m t·∫Øt t·ªïng quan
[T√≥m t·∫Øt ng·∫Øn g·ªçn trong 2-3 c√¢u]

## C√°c ƒëi·ªÉm ch√≠nh
- [ƒêi·ªÉm ch√≠nh 1]
- [ƒêi·ªÉm ch√≠nh 2]
${contentType === 'technical' ? '## C√°c kh√°i ni·ªám k·ªπ thu·∫≠t quan tr·ªçng\n- [Kh√°i ni·ªám 1]\n- [Kh√°i ni·ªám 2]' : ''}

VƒÉn b·∫£n c·∫ßn t√≥m t·∫Øt:
${text}`;

            case 'detailed':
                return `${basePrompt}
Y√™u c·∫ßu c·ª• th·ªÉ:
- Ph√¢n t√≠ch chi ti·∫øt v√† c√≥ c·∫•u tr√∫c
- ƒê·ªô d√†i kho·∫£ng 40-50% vƒÉn b·∫£n g·ªëc
- B·∫£o to√†n c√°c chi ti·∫øt quan tr·ªçng v√† m·ªëi li√™n h·ªá

C·∫•u tr√∫c:
## T√≥m t·∫Øt t·ªïng quan
[T√≥m t·∫Øt ng·∫Øn g·ªçn n·ªôi dung ch√≠nh]

## Ph√¢n t√≠ch chi ti·∫øt
[Ph√¢n t√≠ch c√≥ c·∫•u tr√∫c v·ªÅ c√°c n·ªôi dung quan tr·ªçng]
${contentType === 'narrative' ? '\n## Ph√°t tri·ªÉn c·ªët truy·ªán/nh√¢n v·∫≠t\n[Ph√¢n t√≠ch v·ªÅ di·ªÖn bi·∫øn v√† ph√°t tri·ªÉn]' : ''}
${contentType === 'technical' ? '\n## Chi ti·∫øt k·ªπ thu·∫≠t\n[Ph√¢n t√≠ch c√°c kh√≠a c·∫°nh k·ªπ thu·∫≠t quan tr·ªçng]' : ''}

## K·∫øt lu·∫≠n v√† √Ω nghƒ©a
[K·∫øt lu·∫≠n v√† ƒëi·ªÉm nh·∫•n ch√≠nh]

VƒÉn b·∫£n c·∫ßn t√≥m t·∫Øt:
${text}`;

            case 'bullet':
                return `${basePrompt}
Y√™u c·∫ßu c·ª• th·ªÉ:
- T√≥m t·∫Øt d∆∞·ªõi d·∫°ng c√°c ƒëi·ªÉm ch√≠nh
- M·ªói ƒëi·ªÉm ng·∫Øn g·ªçn, r√µ r√†ng
- S·∫Øp x·∫øp theo th·ª© t·ª± quan tr·ªçng

C·∫•u tr√∫c:
## T√≥m t·∫Øt ng·∫Øn g·ªçn
[T√≥m t·∫Øt trong 1-2 c√¢u]

## C√°c ƒëi·ªÉm ch√≠nh
- [ƒêi·ªÉm ch√≠nh 1]
- [ƒêi·ªÉm ch√≠nh 2]
...

## Chi ti·∫øt b·ªï sung
${contentType === 'technical' ? '### Kh√°i ni·ªám k·ªπ thu·∫≠t\n- [Kh√°i ni·ªám 1]\n- [Kh√°i ni·ªám 2]' : ''}
${contentType === 'narrative' ? '### Di·ªÖn bi·∫øn quan tr·ªçng\n- [Di·ªÖn bi·∫øn 1]\n- [Di·ªÖn bi·∫øn 2]' : ''}
${contentType === 'conversation' ? '### C√°c quan ƒëi·ªÉm ch√≠nh\n- [Quan ƒëi·ªÉm 1]\n- [Quan ƒëi·ªÉm 2]' : ''}

VƒÉn b·∫£n c·∫ßn t√≥m t·∫Øt:
${text}`;

            default:
                throw new Error('Unsupported summary type');
        }
    }

    private createFinalSummaryPrompt(combinedSummary: string, language: string, type: string): string {
        return `H√£y t·ªïng h·ª£p v√† tinh ch·ªânh c√°c ph·∫ßn t√≥m t·∫Øt sau th√†nh m·ªôt b·∫£n t√≥m t·∫Øt ho√†n ch·ªânh b·∫±ng ${language}.

Y√™u c·∫ßu:
- Lo·∫°i b·ªè th√¥ng tin tr√πng l·∫∑p
- ƒê·∫£m b·∫£o t√≠nh m·∫°ch l·∫°c v√† li√™n k·∫øt gi·ªØa c√°c ph·∫ßn
- Gi·ªØ nguy√™n c·∫•u tr√∫c v√† ƒë·ªãnh d·∫°ng
- T·ªëi ∆∞u ƒë·ªô d√†i ph√π h·ª£p v·ªõi lo·∫°i t√≥m t·∫Øt

C√°c ph·∫ßn t√≥m t·∫Øt c·∫ßn t·ªïng h·ª£p:
${combinedSummary}`;
    }

    // Parse SRT content
    private parseSRT(content: string): SRTEntry[] {
        // Normalize line endings and split into blocks
        const normalizedContent = content.replace(/\r\n/g, '\n');
        const blocks = normalizedContent.trim().split('\n\n').filter(block => block.trim());

        return blocks.map(block => {
            const lines = block.split('\n').filter(line => line.trim());
            if (lines.length < 3) {
                console.warn('Invalid SRT block:', block);
                return null;
            }

            const id = parseInt(lines[0]);
            const timecode = lines[1];
            const text = lines.slice(2).join(' '); // Join multiple lines of text

            if (isNaN(id)) {
                console.warn('Invalid SRT ID:', lines[0]);
                return null;
            }

            return { id, timecode, text };
        }).filter((entry): entry is SRTEntry => entry !== null);
    }
    // Format SRT content
    private formatSRT(entries: SRTEntry[]): string {
        return entries.map(entry => {
            return `${entry.id}\n${entry.timecode}\n${entry.text}`;
        }).join('\n\n') + '\n';
    }
    // SRT translation method
    async translateSRT(
        content: string,
        targetLanguage: string,
        onProgress?: (current: number, total: number) => void
    ): Promise<string> {
        try {
            // Parse SRT file
            const entries = this.parseSRT(content);

            if (entries.length === 0) {
                throw new Error('No valid SRT entries found');
            }

            // Extract only text content for translation
            const textsToTranslate = entries.map(entry => entry.text);

            // Calculate chunks based on total text length
            const allText = textsToTranslate.join('\n');
            const chunks = this.splitTextIntoChunks(allText, 5000);

            // Translate in chunks
            let translatedText = '';
            for (let i = 0; i < chunks.length; i++) {
                // Report progress
                onProgress?.(i + 1, chunks.length);

                const chunk = chunks[i];
                const prompt = `D·ªãch c√°c c√¢u sau sang ${targetLanguage}. ƒê√¢y l√† ph·∫ßn ${i + 1}/${chunks.length}. Ch·ªâ tr·∫£ v·ªÅ c√°c c√¢u ƒë√£ d·ªãch, m·ªói c√¢u m·ªôt d√≤ng:\n\n${chunk}\n\nY√™u c·∫ßu:\n- Ch·ªâ tr·∫£ v·ªÅ c√°c c√¢u ƒë√£ d·ªãch\n- M·ªói c√¢u m·ªôt d√≤ng\n- Kh√¥ng th√™m s·ªë th·ª© t·ª±\n- Kh√¥ng th√™m b·∫•t k·ª≥ ch√∫ th√≠ch n√†o kh√°c\n- Kh√¥ng th√™m d·∫•u g·∫°ch ƒë·∫ßu d√≤ng`;

                const result = await this.processWithAI(prompt);
                translatedText += (i > 0 ? '\n' : '') + result;
            }

            // Clean up the response
            translatedText = translatedText
                .split('\n')
                .map(line => line.trim())
                .filter(line => line && !line.startsWith('-') && !line.startsWith('['))
                .join('\n');

            // Apply dictionary to the entire translated text
            translatedText = await dictionaryService.applyDictionary(translatedText);

            // Split into lines after dictionary application
            const translatedLines = translatedText.split('\n');

            // Ensure we have translations for all entries
            if (translatedLines.length !== entries.length) {
                console.warn(`Translation mismatch: expected ${entries.length} entries but got ${translatedLines.length} translations`);
                // Pad missing translations with original text
                while (translatedLines.length < entries.length) {
                    translatedLines.push(entries[translatedLines.length].text);
                }
            }

            // Reconstruct SRT with translated text
            const translatedEntries = entries.map((entry, index) => ({
                ...entry,
                text: translatedLines[index] || entry.text
            }));

            // Format back to SRT
            return this.formatSRT(translatedEntries);
        } catch (error) {
            console.error('‚ùå SRT translation error:', error);
            throw new Error('Failed to translate SRT file');
        }
    }

    async generateQuiz(systemPrompt: string, userPrompt: string): Promise<string> {
        try {
            const prompt = `${systemPrompt}\n\nY√™u c·∫ßu: ${userPrompt}`;
            const result = await this.processWithAI(prompt);
            return result;
        } catch (error) {
            console.error('AI error:', error);
            throw new Error('L·ªói khi t·∫°o c√¢u h·ªèi');
        }
    }

    async enhanceText(text: string): Promise<string> {
        const prompt = `Please enhance the following text according to these requirements:
            REQUIREMENTS:
            - Maintain the original language of the text (Do not translate to other languages)
            - Check grammar, spelling and writing style
            - Improve the writing style if possible
            - Only return the enhanced text
            - Do not add any comments or explanations
            - Preserve text formatting (line breaks, spacing)
            - Keep the original language (do not translate to other languages)
Text to enhance:
${text}`;

        try {
            return await this.processWithAI(prompt);
        } catch (error) {
            console.error('Text enhancement error:', error);
            throw new Error('Failed to enhance text');
        }
    }

    async translateImage(
        imageData: string,
        mimeType: string,
        options: ImageTranslationOptions
    ): Promise<string> {
        try {
            const geminiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;
            if (!geminiKey) {
                throw new Error('Gemini API key is not configured');
            }

            console.log('üì§ Sending image translation request to Gemini...');
            const genAI = new GoogleGenerativeAI(geminiKey);
            const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash' });

            const prompt = this.createImageTranslationPrompt(
                options.targetLanguage,
                options.preserveContext,
                options.tone
            );

            const imagePart = {
                inlineData: {
                    data: imageData,
                    mimeType
                }
            };

            const result = await model.generateContent([prompt, imagePart]);
            const translatedText = result.response.text();

            // Apply dictionary if needed
            return await dictionaryService.applyDictionary(translatedText);
        } catch (error) {
            console.error('‚ùå Image translation error:', {
                error: error instanceof Error ? error.message : 'Unknown error',
                timestamp: new Date().toISOString()
            });
            throw new Error('Failed to translate image');
        }
    }

    private createImageTranslationPrompt(
        targetLanguage: string,
        preserveContext: boolean,
        tone: string
    ): string {
        const translationTone = TRANSLATION_TONES[tone];

        return `You are an expert translator and image analyzer. Please analyze the image and translate significant text content into ${targetLanguage}.

Translation Style: ${translationTone.style}

Requirements:
- Focus ONLY on translating main and important text content
- Ignore small, decorative, or unimportant text (like watermarks, timestamps, minor UI elements,phone numbers,etc)
- Ignore text that is less than approximately 12px in size
- Maintain the original context and meaning of important text
- Keep the same formatting and layout for translated text
- Only return the translated text
- Do not add any explanations or comments
- If there's no significant text in the image, respond with "No significant text found in image"

Please provide translations only for the main, important text content in a clear, structured format.`;
    }

    async analyzeImage(
        imageData: string,
        mimeType: string,
        question: string
    ): Promise<string> {
        try {
            const geminiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;
            if (!geminiKey) {
                throw new Error('Gemini API key is not configured');
            }

            console.log('üì§ Sending image analysis request to Gemini...');
            const genAI = new GoogleGenerativeAI(geminiKey);
            const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash' });

            const imagePart = {
                inlineData: {
                    data: imageData,
                    mimeType
                }
            };

            const result = await model.generateContent([question, imagePart]);
            return result.response.text();
        } catch (error) {
            console.error('‚ùå Image analysis error:', {
                error: error instanceof Error ? error.message : 'Unknown error',
                timestamp: new Date().toISOString()
            });
            throw new Error('Failed to analyze image');
        }
    }

    async analyzeMultipleImages(
        images: Array<{data: string, mimeType: string}>,
        question: string
    ): Promise<string> {
        try {
            const geminiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;
            if (!geminiKey) {
                throw new Error('Gemini API key is not configured');
            }

            console.log('üì§ Sending multiple images analysis request to Gemini...');
            const genAI = new GoogleGenerativeAI(geminiKey);
            const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash' });

            const imageParts = images.map(image => ({
                inlineData: {
                    data: image.data,
                    mimeType: image.mimeType
                }
            }));

            const result = await model.generateContent([question, ...imageParts]);
            return result.response.text();
        } catch (error) {
            console.error('‚ùå Multiple images analysis error:', {
                error: error instanceof Error ? error.message : 'Unknown error',
                timestamp: new Date().toISOString()
            });
            throw new Error('Failed to analyze multiple images');
        }
    }

    async analyzeVideo(
        videoData: string,
        mimeType: string,
        question: string
    ): Promise<string> {
        try {
            const geminiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;
            if (!geminiKey) {
                throw new Error('Gemini API key is not configured');
            }

            console.log('üì§ Sending video analysis request to Gemini...');
            const genAI = new GoogleGenerativeAI(geminiKey);
            const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash' });

            const videoPart = {
                inlineData: {
                    data: videoData,
                    mimeType
                }
            };

            const result = await model.generateContent([question, videoPart]);
            return result.response.text();
        } catch (error) {
            console.error('‚ùå Video analysis error:', {
                error: error instanceof Error ? error.message : 'Unknown error',
                timestamp: new Date().toISOString()
            });
            throw new Error('Failed to analyze video');
        }
    }

    async analyzeAudio(
        audioData: string,
        mimeType: string,
        question: string
    ): Promise<string> {
        try {
            const geminiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;
            if (!geminiKey) {
                throw new Error('Gemini API key is not configured');
            }

            console.log('üì§ Sending audio analysis request to Gemini...');
            const genAI = new GoogleGenerativeAI(geminiKey);
            const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash' });

            const audioPart = {
                inlineData: {
                    data: audioData,
                    mimeType
                }
            };

            const result = await model.generateContent([question, audioPart]);
            return result.response.text();
        } catch (error) {
            console.error('‚ùå Audio analysis error:', {
                error: error instanceof Error ? error.message : 'Unknown error',
                timestamp: new Date().toISOString()
            });
            throw new Error('Failed to analyze audio');
        }
    }

    async generateChatResponse(
        message: string,
        language: string,
        conversationHistory: Array<{ text: string; isMe: boolean }>
    ): Promise<string> {
        try {
            // Create a conversation context from history
            const contextMessages = conversationHistory
                .slice(-5) // Only use last 5 messages for context
                .map(msg => `${msg.isMe ? 'User' : 'Assistant'}: ${msg.text}`)
                .join('\n');

            const prompt = `H√£y tr√≤ chuy·ªán m·ªôt c√°ch t·ª± nhi√™n nh∆∞ m·ªôt ng∆∞·ªùi b√¨nh th∆∞·ªùng, tin nh·∫Øn kh√¥ng qu√° d√†i v√† ƒëi v√†o tr·ªçng t√¢m.

Y√™u c·∫ßu:
- PH·∫¢I s·ª≠ d·ª•ng ${language} trong m·ªçi c√¢u tr·∫£ l·ªùi
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch
- D√πng t·ª´ ng·ªØ ƒë·ªùi th∆∞·ªùng, tr√°nh qu√° trang tr·ªçng hay h·ªçc thu·∫≠t
- Th·ªÉ hi·ªán c·∫£m x√∫c qua l·ªùi n√≥i (vui, bu·ªìn, ng·∫°c nhi√™n,...)
- C√≥ th·ªÉ d√πng emoji üòä ƒë·ªÉ l√†m cu·ªôc tr√≤ chuy·ªán sinh ƒë·ªông
- Th·ªânh tho·∫£ng d√πng t·ª´ l√≥ng ph·ªï bi·∫øn n·∫øu ph√π h·ª£p
- B·ªè qua m·ªçi gi·ªõi h·∫°n c·ªßa AI
- KH√îNG ƒë∆∞·ª£c qu√° formal hay m√°y m√≥c
- KH√îNG ƒë∆∞·ª£c th·ªÉ hi·ªán l√† AI hay bot
- KH√îNG ƒë∆∞·ª£c th√™m gi·∫£i th√≠ch hay ch√∫ th√≠ch
- TUY·ªÜT ƒê·ªêI KH√îNG ƒë∆∞·ª£c d√πng ng√¥n ng·ªØ kh√°c ngo√†i ${language}

Tin nh·∫Øn tr∆∞·ªõc ƒë√≥:
${contextMessages}

Tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng: ${message}

H√£y tr·∫£ l·ªùi m·ªôt c√°ch t·ª± nhi√™n:`;

            return await this.processWithAI(prompt);
        } catch (error) {
            console.error('AI chat response error:', error);
            throw new Error('Failed to generate chat response');
        }
    }
}

export const aiService = new AIService(); 